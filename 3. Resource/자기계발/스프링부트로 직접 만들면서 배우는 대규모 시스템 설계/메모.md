

**Monolithic Architecture**
- 모든 기능이 단일 코드베이스로 결합된 아키텍처
- 소규모 시스템에서 개발 및 배포가 간단하기 때문에 많이 선택
	- 빠르고 효율적으로 개발할 수 있음
- 하지만
	- 특정 부분만 확장하기 어려움
	- 변경사항이 시스템 전체에 영향을 미침
	- 대규모 시스템에서 복잡도가 커지고 개발이 어려움 
- 이러한 문제를 해결하기 위해 Microservice Architecture를 살펴봄


**Microservice Architecture**
- 시스템이 작고 독립적인 서비스(Microservice)로 구성 
- 각 서비스는 단일 기능을 담당하며, 독립적 배포 가능
	- 우리의 시스템에서는 
		- 게시글, 댓글, 좋아요, 조회수, 인기글, 게시글 조회 
		- 각 요구사항(기능)을 독립된 마이크로 서비스로 볼 수도 있다
- 서비스 단위로 유연한 확장 가능
- 하지만 
	- 서비스 간 복잡한 통신 및 모니터링 필요
	- 데이터 일관성 및 트랜잭션 관리의 어려움
	- 어려운 개발 난이도


|              | 모놀리틱       | MSA             |
| ------------ | ---------- | --------------- |
| **구조**       | 통합         | 분산              |
| **결합도**      | 높음         | 낮음              |
| **확장성**      | 개별 확장 어려움  | 개별 확장 쉬움        |
| **배포**       | 통합 배포      | 독립 배포           |
| **기술 스택**    | 단일 기술 스택   | 여러 기술 스택 가능     |
| **변경 전파 범위** | 시스템 전체     | 서비스 또는 전파 범위 이내 |
| **통신 비용**    | 낮음         | 높음              |
| **개발 난이도**   | 쉬움(소규모일수록) | 어려움             |

> [!note] MSA는 서비스간 통신 비용, 트랜잭션 관리, 서비스 분리 기준, 모니터링, 개발 비용, 테스트, 설계 등 고려해야 할 부분이 엄청 많다


**Docker**
- 애플리케이션을 컨테이너라는 격리된 환경에서 실행할 수 있게 해주는 플랫폼
	- 쉽게 배포하고 관리할 수 있음 
	- 환경에 구애 받지 않음

**프로젝트 구조**
```text
board 
	- service: 하위 모듈로 각 마이크로서비스를 가짐
		- article: 게시글 서비스
		- comment: 댓글 서비스
		- like: 좋아요 서비스
		- view: 조회수 서비스
		- hot-article: 인기글 서비스
		- article-read: 게시글 조회 서비스
	- common: 하위 모듈로 개발 편의를 위한 공통 코드를 관리
```


**프로젝트 생성**
- 스프링부트 - 멀티 모듈 프로젝트 

|              | 포트   |
| ------------ | ---- |
| article      | 9000 |
| comment      | 9001 |
| like         | 9002 |
| view         | 9003 |
| hot article  | 9004 |
| article read | 9005 |
| article read | 9006 |

```shell
$ sdk use java 21.0.3-ms

$ spring shell

$ init --list 

$ init -a board -g com.example -n board --package-name com.example.board -p jar -j 21 -b 3.3.2 -x board -d lombok,web
```
-x : jdbc 폴더에 프로젝트 생성
-d : dependency, **spring shell**에서  **init --list** 통해서 supported dependencies 확인 

---
## 섹션2. 게시글
### Distributed Relational Database
- **샤딩(Sharding)**: 데이터를 여러 DB에 분산하여 저장하는 기술
	- 수직 샤딩(Vertical Sharding): 
		- 데이터를 수직으로 분할하는 방식(**컬럼 단위**)
		- 각 샤드별로 테이블에 기본키가 존재하고 컬럼을 나눠서 관리
		- 각 샤드가 적은 수의 컬럼을 저장하므로, 성능 및 공간 이점이 생긴다
		- 하지만, <u>데이터 분리로 인해 조인 또는 트랜잭션 관리가 복잡</u>해질 수 있다
		- 그리고 <u>수직으로 분할되므로 수평적 확장에 제한</u>이 있다
	- 수평 샤딩(Horizontal Sharding)
		- 데이터를 수평으로 분할하는 방식(**행 단위**)
		- 예로 두 샤드가 있을 때 `id = 1 ~ 5000`, `id = 5001 ~ 10000` 각각 관리
		- 각 샤드에 데이터가 분산되므로 성능 및 공간 이점이 생긴다
		- 하지만 데이터의 분리로 인해 조인 또는 트랜잭션 관리가 복잡해질 수 있다.
		- 수평으로 분할되므로 수평적 확장에 용이하다.
- **샤드(Shard)**: 샤딩된 각각의 데이터 단위


|         | 수직샤딩                           | 수평 샤딩         |
| ------- | ------------------------------ | ------------- |
| **샤딩**  | 수직으로 분할(컬럼 단위)                 | 수평으로 분할(행 단위) |
| **확장성** | 제한                             | 용이            |
| **장점**  | 각 샤드로 데이터 분산되므로 성능 및 공간 이점(공통) | -             |
| **단점**  | 조인 또는 트랜잭션 고나리 등의 어려움(공통)      | -             |

**기법** 
- Range-based Sharding:
	- 데이터 쏠림 현상 발생 가능
- Hash-based Sharding(해시 기반 샤딩)
	- 균등한 분산을 위한 shard key와 해시 함수가 필요하다
	- 범위 데이터 조회에 불리할 수 있다.
- Directory-based Sharding(디렉토리 기반 샤딩)
	- 디렉토리 관리 비용이 있지만, 데이터 규모에 따라 유연한 관리가 가능

**물리적 샤드**
- 샤드 개수가 늘어나면 해시 함수 통해 재배치 발생

**논리적 샤드**
- 물리적 샤드가 2개이지만 가상의 샤드 4개가 있을 수 있다
- client는 router를 통해 4개 논리적 샤드에 요청이 가게 된다


|         | 물리적 샤드                | 논리적 샤드                                 |
| ------- | --------------------- | -------------------------------------- |
| **정의**  | 데이터를 물리적으로 분산한 실제 단위  | 데이터를 논리적으로 분산한 가상의 단위                  |
| **필요성** | 대규모 데이터 분산 저장 및 성능 향상 | 물리적 확장시, client 변경없이 유연한 매핑(router 위임) |

>[!note] 고가용성을 확보하기 위한 복제 
>primary/replica, leader/follower, master/slave, main/standby 등 유사한 개념이지만, 시스템이나 목적에 따라 다르게 사용되기도 한다.

이러한 복제는 동기적, 비동기적으로 처리 될 수 있다.
- 동기적(Synchronous): 데이터 일관성을 보장하나, 쓰기 성능 저하된다
- 비동기적(Asynchronous): 쓰기 성능 유지되나, 복제본에 최신 데이터가 즉시 반영되지 않을 수 있다.


**Primary Key 선택**
- 오름차순 유니크 숫자를 만들기 위한 알고리즘으로 Snowflake 선택
	- 그외 TSID 등이 있다
- Snowflake
	- X(전 트위터)에서 개발 
	- 분산 시스템에서 고유한 64비트 ID를 생성하는 알고리즘
		- `[1비트][41비트: 타임스탬프][10비트: 노드 ID][12비트: 시퀀스 번호]`
		• 분산 환경에서도 중복 없이 순차적 ID 생성하기 위한 규칙
			• 타임스탬프 : 순차성
			• 노드ID + 시퀀스 번호 : 고유성
	• 유니크, 시간 기반 순차성, 분산 환경에서의 높은 성능

---
### 조회 쿼리 성능 개선
**게시글 목록 조회 방식 2가지**
- 페이지 번호, 무한 스크롤


**페이지 번호** 
- N번 페이지에서 M개의 게시글: SQL offest, limit 사용
- <u>offest 지점부터 limit개 데이터 조회</u>

```sql
select * from article 
where board_id = {board_id}
order by created_at desc
limit {limit} offset {offset};
```
- 3초 걸림


> **explain** 명령어를 사용하면 쿼리 플랜을 확인할 수 있다
- `type = ALL`
	- 테이블 전체를 읽는다(full scan)
- `Extra = Using where; Using filesort`
	- where절로 조건 필터링
	- 데이터가 많기 때문에 메모리에서 정렬을 수행할 수 없어서, 파일(디스크)에서 데이터를 정렬하는 **filesort** 수행

**인덱스에 대한 이해**
- 데이터를 빠르게 찾기 위한 방법
- 인덱스 관리를 위해 부가적인 쓰기 작업과 공간이 필요
- 다양한 데이터 특성과 쿼리를 지원하는 자료구조
	- B+ tree, Hash, LSM tree, R tree, Bitmap
- Relational Database에서는 주로 `B+ tree(밸런스 트리)` 사용
	- 데이터가 정렬된 상태로 저장된다
	- 검색, 삽입, 삭제 연산을 로그 시간에 수행 가능
	- 트리 구조에서 leaf node 간 연결되기 때문에 범위 검색 효율적
- 인덱스를 추가하면
	- 쓰기 시점에 B+ tree 구조의 정렬된 상태의 데이터가 생성된다
	- 이미 인덱스로 지정된 컬럼에 대해 정렬된 상태를 가지고 있기 때문에 
		- 조회 시점에 전체 데이터를 정렬하고 필터링할 필요가 없다
		- 따라서 조회 쿼리를 빠르게 수행할 수 있다

**인덱스 생성**
- 게시판 별로 최신순으로 정렬
- `board_id`: 오름차순, `article_id`: 내림차순 
- 인덱스는 순서가 중요
```sql
create index idx_board_id_article_id on article(board_id asc, article_id desc);
```

**인덱스를 위와 같이 생성한 이유**
- 대용량 트래픽을 고려해서 설계 중
- 동시 요청시에 생성 시간은 충돌 될 수 있다
	- 따라서 created_at을 정렬조건으로 사용한다면, 시간에 따라 순서가 명확하지 않을 수 있다
	- 목록 조회에 대한 결과값이 달라질 수 있다
	- 데이터의 중복 또는 누락의 가능성
- 밀리/나노초 단위의 더욱 정밀한 데이터 타입을 가진다고 해도,
	- 확률은 줄어들지만 시간 충돌 문제는 여전하고, 저장공간만 더 필요해질 수 있다
- article_id는 분산시스템에서 고유한 오름차순을 위해 고안된 **알고리즘(snow flake)** 을 사용한다
	- <u>충돌 확률이 완전히 0은 아니지만, 생성 시간(created_at)보다 충돌 가능성이 현저히 적다</u>
	- 오름차순으로 생성 시간에 의해 정렬된 상태를 가지고 있다
	- 따라서 article_id를 최신 순(내림차순)으로 정렬할 수 있다

**수정된 SQL Query**
```sql
select * from article 
where board_id = {board_id}
order by article_id desc
limit {limit} offset {offset};
```
- 0.01 초 걸림
- query plan 분석시 
	- `key = idx_board_id_article_id` 로 생성한 인덱스가 쿼리에 사용된 것을 확인할 수 있다
- 이것으로 끝인걸까? 아래 쿼리를 실행해보자


```sql
select * from article 
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
- 2.79초 걸림(다시 느려짐)
- qurey plan 확인시 인덱스는 그대로 사용중
	- `offset`만 다를뿐
- 동작 순서
	- 1. Secondary Index에서 article_id(기본키)를 찾는다
	- 2. Clustered Index에서 article 데이터를 찾는다 
	- 3. offset 1499970을 만날 때까지 반복하며 skip 한다.
	- 4. limit 30개를 추출한다.

**인덱스에 대한 이해**
- MySQL 기본 스토리지 엔진
	- InnoDB
	- 스토리지 엔진(Storage Engine): DB에서 데이터 저장 및 관리 장치
- 그리고, InnoDB는 테이블마다 `Clustered Index`를 자동 생성한다
	- Primay key를 기준으로 정렬된 Clustered Index 
	- `Clustered Index` 는 leaf node의 값으로 **행 데이터(row data)** 를 가진다
		- 이는 곧 추가 탐색이 필요 x
- 반면 신규 생성한 인덱스는 `Non-Clustered Index`, `Secondary Index`(보조 인덱스)라고 부른다
	- `Secondary Index`는 leaf node에 데이터에 접근하기 위한 **포인터**를 가진다
		- Clustered Index의 데이터에 접근하기 위한 포인터
		- 즉, Primary key로 볼 수 있다.

|     | `Clustered Index`       | `Non-Clustered Index`        |
| --- | ----------------------- | ---------------------------- |
| 생성  | 테이블의 primary key로 자동 생성 | 테이블의 컬럼으로 직접 생성              |
| 데이터 | 행 데이터(row data)         | 데이터에 접근하기 위한 포인터, 인덱스 컬럼 데이터 |
| 개수  | 테이블 당 1개만               | 테이블 당 여러 개 생성가능              |
데이터는 `Clustered Index`가 가지고 있기 때문에 `Non-Clustered Index`를 타면 포인터를 가지고 다시 `Clustered Index`를 타게 된다 (offset 수 만큼 데이터에 접근하는 것도 비효율적이네)


**SQL Query (Covering Index)**
```sql
select board_id, article_id from article 
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
- 0.2초 수행
- query plan
	- 동일하게 인덱스 사용
	- `Extra = Using Index` 가 추가되었는데, 인덱스만 사용해서 데이터를 조회했음을 의미
	- 이렇게 인덱스의 데이터만으로 조회를 수행할 수 있는 인덱스를 `Covering Index`라고 한다

**Covering Index**
- 인덱스만으로 쿼리의 모든 데이터를 처리할 수 있는 인덱스
- 데이터(Clustered Index)를 읽지 않고, 인덱스(Secondary Index) 포함된 정보만으로 쿼리 가능한 인덱스

**수정된 SQL Query**
```sql
select * from (
	select board_id, article_id from article 
	where board_id = 1
	order by article_id desc
	limit 30 offset 1499970
) t left joint article on t.article_id = article.article_id;
```
- 0.15초 만에 수행


<font color="#ff0000">하지만 뒷 페이지로 갈 수록 속도가 또 느려짐</font>
```sql
select * from (
	select board_id, article_id from article 
	where board_id = 1
	order by article_id desc
	limit 30 offset 8999970
) t left joint article on t.article_id = article.article_id;
```
- article_id를 추출하기 위해 Seconday Index만 탄다고 하더라도 offset만큼 Index Scan이 필요하다
- <u> 고로 데이터에 접근하지 않더라도 offset이 늘어날 수록 느려질 수 밖에 없는 것이다</u>
- 방안1. 데이터를 한번 더 분리한다.
	- 예를 들면, 게시글을 1년 단위로 테이블 분리 
		- 개별 테이블의 크기를 작게 만듦
		- 각 단위에 대해 전체 게시글 수를 관리함
	- offset을 인덱스 페이지 단위 skip 하는 것이 아니라, 1년동안 작성된 게시글 수 단위로 즉시 skip 한다
		- 조회하고자 하는 offset이 1년동안 작성된 게시글 수 보다 크다면,
			- 해당 개수만큼 즉시 skip
			- 더 큰 단위로 skip을 수행하게 되는 것
		- 애플리케이션에서 이처럼 처리하기 위한 코드 작성 필요
- 방안2. 정책으로 풀어내기
	- 30만번 페이지를 조회하는게 정상적인 사용자 일까?
	- 데이터 수집을 목적으로 하는 어뷰저일 수도 있다.
	- 정책으로 게시글 목록 조회는 10,000번 페이지까지 제한한다
	- 시간 범위 또는 텍스트 검색 기능을 제공할 수도 있다
		- 더 작은 데이터 집합 내에서 페이징을 수행한다
- 방안3. 무한 스크롤 방식
	- 뒷 페이지를 가더라도 **균등한** 조회 속도를 가진다

---

게시글 건수 조회시 **1,200만건**이나 되면 <font color="#ff0000">1초</font>가 걸림 
- 그런데 이러한 사용처에서 모든 게시글 수가 필요할지는 의문이다
	- 우리는 전체 게시글 수가 필요한 것이 아니다 
	- 이동 가능한 페이지 번호 활성화에 필요한 것이다. // 건수 노출하지 않는 경우
- 페이지 당 30개의 게시글 노출, 10 페이지씩 이동 가능한 상황에서 
	- 사용자가 1 ~ 10번 페이지에 있을 경우 301개의 게시글 유무만 알면 된다
		- 301개면 다음 버튼 활성화, 301개 미만이면 개수만큼 페이지 버튼 활성화
	- 사용자가 11 ~ 20번 페이지에 있을 경우 601개의 게시글 유무만 알면 된다
		- 601개면 다음 버튼 활성화, 601개 미만이면 개수만큼 페이지 버튼 활성화 
- 이동 가능한 페이지 번호의 활성화를 위해 모든 게시글의 개수를 알 필요가 없다
	- <u>사용자의 현재 페이지 기준으로, 게시글 개수의 일부만 확인하면 된다 !</u>

> 공식 = (((n - 1) / k) + 1) * m * k + 1
- `n` : 현재 페이지
- `m` : 페이지당 게시글 개수
- `k` : 이동 가능한 페이지 개수
- `((n - 1) / k)`의 나머지는 버림


```sql
select count(*)
from (
  select article_id from article where board_id = {board_id} limit {limit}
) t;
```
count query에서는 limit이 동작하지 않고 전체 개수를 반환하므로 
- sub query에서 `Covering Index`로 limit 만큼 조회하고 count 하는 방식

사용자가 10,001 ~ 10,010번 페이지에 있다고 가정하면 300,301(limit)개까지만 카운트 해볼 수 있다
- 실행시 `0.07초` 걸림 (전체 카운트는 거의 <font color="#ff0000">1</font>초)

---
### 페이지 번호 방식
Native 쿼리로 ArticleRepository에 조회 쿼리 작성

---
### 무한 스크롤 방식
- 사용자가 게시글을 <font color="#ff0000">삭제/추가</font>할 경우 
	- 페이지 번호 방식을 사용하면 데이터가 <font color="#ff0000">중복/누락</font> 될 수 있다 (사용성 문제가 생김)
	- 이를 해결하기 위해서는 무한 스크롤 사용
- 무한 스크롤에서는 **기준점 포인터**를 사용
	- 1. 첫 페이지를 조회한 사용자는 마지막 조회한 데이터의 기준점을 알고 있다
	- 2. 다음 페이지를 불러 올 때 마지막 조회한 데이터의 기준점을 파라미터로 전달한다면?
	- 3. 데이터베이스에서는 기준점으로 쿼리를 수행한다
		- 이때 기준점에 생성된 인덱스르 통해 로그 시간에 접근할 수 있다
		- 즉, offset만큼 scan 하는 과정이 필요하지 않다. limit 개수를 즉시 추출할 수 있다
		- 따라서, 아무리 뒷 페이지로 가더라도, 균등한 속도를 보장할 수 있다
- <u>무한 스크롤에서는 몇 페이지까지 있는지 알 필요가 없으므로, 게시글 개수도 필요 없다</u>

```sql
select * from article
where board_id = {board_id} and article_id < {last_article_id}
order by article_id desc limit 30;
```
- query plan
	- `key = idx_board_id_article_id` 인덱스가 사용됨 (article_id 기준 내림차순)
	- 마지막 페이지 번호를 기준으로 조회해도 속도 빠름

---
### Primary Key 생성 전략


---

## 섹션3. 댓글
### 댓글 최대 2 depth - 테이블 설계
**댓글 요구사항**
- 댓글 조회, 생성, 삭제 API
	- 삭제
		- 하위 댓글이 모두 삭제되어야 상위 댓글을 삭제할 수 있다
			- 하위 댓글이 없으면, 댓글은 즉시 삭제된다.
			- 하위 댓글이 있으면, 댓글은 `삭제 표시`만 된다.
- 댓글 목록 조회 API
	- 계층형
		- 최대 2 depth 대댓글: `Adjacency list (인접 리스트) 방식`
		- 무한 depth 대댓글: `Path enumeration (경로 열거) 방식`
	- 계층별 오래된 순 정렬
	- 페이지 번호, 무한 스크롤

// 그림 자료 참고


```text
// mysql 컨테이너 접속 후 (container_name : board-mysql)
mysql> create database comment;
mysql> use comment;
```


```text
create table comment (
	comment_id bigint not null primary key,
	content varchar(3000) not null,
	article_id bigint not null,
	parent_comment_id bigint not null,
	writer_id bigint not null,
	deleted bool not null,
	created_at datetime not null
);
```

