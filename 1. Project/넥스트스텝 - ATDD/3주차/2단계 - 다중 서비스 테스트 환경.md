> [!info]
> - Dockerfile을 개별로 잡은 이유는 프로젝트마다 환경이 다를 수 있기 때문이다
> - docker-compose에서 context 경로를 기준으로 dockerfile 를 찾아 실행하게 된다

> [!info] 스모크 테스트 
> 스모크 테스트의 핵심은 "애플리케이션이 죽지 않고 살아있는가(Health Check)"와 "주요 진입점이 열려있는가"를 확인하는 것이기 때문입니다.

### 학습 목표 
- `admin`, `reservation`을 Step1의 틀에 추가해 3개 앱 모두 컨테이너로 가동합니다
- 우선 각 앱이 자체 DB를 사용하도록 구성해 200 응답 스모크 테스트를 통과시킨다
- 이후 공용 인프라 DB로 전환하도록 코드/환경 구성을 수정한다
	- `atdd-tests/docker/docker-compose-infra.yml`
- `atdd-tests`에서 `kiosk -> admin -> db` 흐름을 검증하는 E2E 테스트를 작성한다
	- ex. 상품 목록 조회 

### 배경 및 범위
- 이제 다중 서비스 환경으로 확장하고, DB 구성을 단계적으로 단순화한다
- 결제 모킹은 본 단계 범위가 아니다
- 네트워크 / DB 연결성, 기본 엔드 포인트 응답, 간단한 시나리오 검증에 집중한다

### TODO.
- [ ] `repos/`에 `atdd-camping-admin`, `atdd-camping-reservation` 동기화
- [ ] `dockerfiles/Dockerfile-admin`, `dockerfiles/Dockerfile-reservation` 준비
- [ ] 앱 compose에 `admin`, `reservation` 추가(초기: 각 앱 전용 DB 포함)
- [ ] `atdd-tests`에서 `admin`, `reservation` 스모크 테스트(200 응답) 추가/통과
- [ ] 인프라 compose(DB) 기동 후, 앱 compose가 공용 네트워크 `atdd-net`을 사용하도록 전환
- [ ] 각 앱이 공용 DB `atdd-db`를 참조하도록 코드/환경 수정 후 스모크 재통과
- [ ] `kiosk → admin → DB` E2E 테스트 작성·통과(예: 상품 목록 조회)

> [!warning] 
> docker-compose-infra 에서는 MySQL 8.0 을 사용하라고 나오지만, atdd-camping-admin 과, atdd-camping-reservation 에는 MySQL 관련 JDBC Driver 가 없음

- 📣 해결 방법(아래 두 방법 중 하나 선택하기)
	- docker-compose-infra 에서 mysql을 h2로 변경해서 진행하기. (1단계)
	- 2단계부터는 mysql로 통합해서 진행하기.

### 요구사항 
**1)`admin`/`reservation` 추가**
- [ ] `repos/` 하위에 두 서비스 클론/동기화
- [ ] Dockerfile 준비: `dockerfiles/Dockerfile-admin`, `dockerfiles/Dockerfile-reservation`.
- [ ] 앱 compose(`atdd-tests/docker/docker-compose.yml`)에 서비스를 추가한다.
- [ ] DB는 아래 3번에서 진행할 예정이니 지금은 무시한다.
- [ ] 200 응답 스모크 테스트를 통과시키다.

**2) 애플리케이션 기동 및 e2e 테스트 통과**
- [ ] 목적: `kiosk → admin → DB` 동작 여부를 확인한다. 각 애플리케이션을 기동해 전용 DB에 정상 연결되는지 확인하고 스모크/E2E 테스트를 통과시킨다.
- [ ] 시나리오 예시
    - `admin` 로그인 API(`/auth/login`)를 호출해 인증 토큰/쿠키를 발급받는다.
    - `kiosk`의 상품 목록 엔드포인트(`/api/products`)를 호출한다(내부적으로 `admin`을 통해 DB 조회).
    - 기대값: 상태코드 200, 응답 배열 길이 ≥ 1, 주요 필드 존재 여부 확인.
- 힌트: `kiosk`는 인증이 필요하므로 사전에 인증 정보를 받아와야 한다. `admin` 로그인으로 발급된 `AUTH_TOKEN`(쿠키/헤더)을 이후 요청에 포함한다.

```text
GET "/api/products" 요청을 보낸다

# AdminClient
@Value("${kiosk.admin.base-url}")  
private String adminBaseUrl;

authHeaders() -> getCookieHeader() 
-> (AdminAuthClient에 쿠키 헤더가 null이면) getToken() 호출

@Value("${kiosk.admin.base-url}")  
private String adminBaseUrl;  
  
@Value("${kiosk.admin.auth.username:admin}")  
private String username;  
  
@Value("${kiosk.admin.auth.password:admin123}")  
private String password;  
  
@Value("${kiosk.admin.auth.login-path}")  
private String loginPath;  
  
@Value("${kiosk.admin.auth.cookie-name:AUTH_TOKEN}")  
private String authCookieName;


 
```


---

프로젝트 구조가 독특하다.
- 테스트 디렉터리만 있고, repos에 배포할 프로젝트 동기화, infra에서는 dockerfile/docker-compose 기반 구성

Q. Shell Script vs Gradle 

Q. dependency, tasks 분리해서 관리하는 방법
- **스크립트 분리(Script Plugins)** 
	- `infra.gradle.kts`와 같은 형태로 분리 가능 
	- 메인인 build.gradle.kts에는 `apply(from = "gradle/infra.gradle.kts")`를 추가한다
	- 

---

Q. dockerfile을 개별적으로 만드는데 프로젝트 구분은 어떻게 하는가?
```text
# Build Jar
FROM eclipse-temurin:17-jdk AS builder
WORKDIR /workspace

# 핵심: 전체가 아닌 현재 프로젝트 폴더의 내용만 복사합니다. 
# (이때 '.'은 docker-compose에서 지정한 'context'📌를 의미합니다)
COPY . .
RUN chmod +x ./gradlew && ./gradlew --no-daemon clean bootJar -x test

# Run Jar
FROM eclipse-temurin:17-jdk
WORKDIR /app
COPY --from=builder /workspace/build/libs/*.jar app.jar
ENV JAVA_OPTS=""
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```
- `Dockerfile-admin`, `Dockerfile-kiosk`, `Dockerfile-reservation` 모두 동일
- 1. `COPY . .`가 문제가 되는 이유
	- 도커 빌드는 **계층(Layer)** 구조입니다.
	- **불필요한 파일 포함**: 다른 프로젝트의 소스 코드까지 컨테이너에 복사됩니다.
	- **캐시 깨짐**: A 프로젝트만 고쳤는데, `COPY . .` 때문에 B, C 프로젝트용 이미지까지 다시 빌드하게 되어 시간이 낭비됩니다.
- 2. 해결책: 프로젝트별 전용 Dockerfile 작성
	- 각 프로젝트가 자기 자신의 폴더만 바라보게 구조를 바꿔야 합니다. `Dockerfile-kiosk`, `Dockerfile-order` 등으로 나누고 docker compose의 context (내부 경로)를 수정하세요.
- 3. 가장 중요한 `docker-compose.yml` 설정
	- Dockerfile을 나누는 것만큼 중요한 게 `context`를 정확히 찍어주는 것입니다. 도커에게 "이 프로젝트의 소스는 여기 있으니 여기서만 놀아라"라고 영역을 정해주는 거죠.

```yaml
services:
  kiosk:
    build:
      context: ./repos/atdd-camping-kiosk # 키오스크 소스 위치
      dockerfile: ../../infra/dockerfiles/Dockerfile-kiosk # 레시피 위치
    ports:
      - "18081:8080"

  order:
    build:
      context: ./repos/atdd-camping-order # 오더 소스 위치
      dockerfile: ../../infra/dockerfiles/Dockerfile-order
    ports:
      - "18082:8080"
```
- dockerfile 경로의 경우 context 위치를 기준으로 찾게 된다 
	- 캐싱에 대해 찾아보자


- 왜 동일한 내용인데 Dockerfile을 분리한걸까?
	- (내생각) 지금은 상관없겠지만 경우에 따라 환경을 달리해야 할 것이다. 
	- 그렇기 때문에 미리 분리를 해두는게 아닌가 싶다 


**1. Context와 `COPY`의 관계 (식재료 창고 비유)**

도커 빌드 과정을 요리에 비유하면 다음과 같습니다.
- **Build Context**: 요리사가 접근할 수 있는 **식재료 창고의 범위**입니다.
- **Dockerfile (`COPY`)**: 창고 안의 재료를 **주방(컨테이너)으로 가져오는 행위**입니다.
    
작성자님이 `context: ./repos/atdd-camping-kiosk`라고 찍어주셨다면, 도커 파일 안에서 `COPY . .`을 할 때 도커는 **해당 폴더 바깥(예: 다른 프로젝트 폴더)은 쳐다보지도 못합니다.** 오직 그 폴더 안의 내용물만 컨테이너로 복사할 수 있는 거죠.


**2. 왜 프로젝트별로 Context를 좁게 잡아야 할까요?**

지금처럼 프로젝트가 3개인 상황에서 `context`를 각각의 프로젝트 폴더로 좁게 잡으면 다음과 같은 이득이 생깁니다.
1. **빌드 속도 향상**: 도커 빌드를 시작할 때 로컬의 파일들을 도커 엔진으로 전송(Sending build context)하는데, 폴더가 작을수록 이 전송 시간이 획기적으로 줄어듭니다.
2. **캐시 효율성**: `Order` 프로젝트의 소스를 고쳐도 `Kiosk` 빌드에는 아무런 영향을 주지 않습니다. 도커는 `Kiosk` 컨텍스트의 파일들이 변하지 않았음을 감지하고 이전 빌드 결과를 그대로 재사용(Using cache)합니다.
3. **경로의 단순화**: 도커 파일 내에서 `COPY . .` 한 줄이면 해당 프로젝트의 `gradlew`, `src` 등을 고민 없이 다 가져올 수 있습니다.


`ScenarioContext` 추가하면서 pico container 의존성이 추가되었다.
- Cucumber가 ScenarioContext 객체를 여러 Steps 클래스에 주입(inject)해줘야 합니다. 이를 위해 cucumber-picocontainer 의존성이 필요합니다. build.gradle.kts 파일을 확인하여 해당 의존성이 있는지
  확인하고, 없다면 추가해주시는 것이 좋습니다
	- `testImplementation("io.cucumber:cucumber-picocontainer:$cucumberVersion")`
	- cucumber-java와 버전 일치하는게 좋다

```java
// 1. 데이터를 담을 바구니 (POJO)
public class TestContext {
    public Response response; // 응답 객체 담기
}

// 2. Step 클래스 A (응답을 담는 곳)
public class StepA {
    private TestContext context;
    public StepA(TestContext context) { this.context = context; } // 생성자 주입

    @When("요청을 보내면")
    public void sendRequest() {
        context.response = ...; // 응답 저장
    }
}

// 3. Step 클래스 B (응답을 검증하는 곳)
public class StepB {
    private TestContext context;
    public StepB(TestContext context) { this.context = context; }

    @Then("응답이 성공한다")
    public void verify() {
        assert context.response.getStatusCode() == 200; // 공유된 데이터 사용
    }
}
```


---

todo 
- repos 하위 프로젝트에 .dockerignore 추가 
- mysql 추가시 계정 tester 생성
- build.gradle.kts에서 tasks를 분리해준다
- 테스트별로 features 디렉터리를 구분한다
- `프로젝트 클론 - 컨테이너 실행 - 테스트 실행 - 자원 정리` 과정 정리하기

// feature에 태그 기능도 있다한다

---


```text
핵심은 새로운 기능 구현 시 기준 스펙이 변경되는 경우가 있는데
이 때 무작정 개선하기 보다는 조금 더 안정적인 방법으로 진행하는데 있습니다!

<code>
1. 신규 기능을 정의하고 설계하기
2. 신규 기능은 기존 스펙을 변경하는 부분을 포함하고 있음
3. 바로 기존 스펙을 변경하지 않고 기존 스펙을 검증하는 테스트를 보완하면서 진행
4. 이 때 기존 테스트를 바로 수정하지 않고 비슷한 테스트를 새로 만들기
5. 이렇게 한 다음 신규 기능을 검증하는 테스트를 만들고 기존 기능의 새로운 스펙을 검증하는 테스트를 구축
6. 그러고 신규 기능을 구현을 완성하면 위 두 테스트는 성공하고 기존 테스트는 실패함
7. 그렇게 성공적으로 기능 구현을 끝내면 기존 테스트는 제거
8. 만약 신규 기능을 구현하다가 꼬이거나 실패할 경우 다시 코드를 돌리는데 이 때 기존 테스트로 기존 기능이 유효한지 보호하기
<code>

이게 점진적으로 코드를 보호하는 테스트를 구축하는 방법인데 
새로운 도메인이라던지 조금 더 공격적으로 신규 기능을 설계하고 진행해보아도 좋을 것 같습니다!

```

```text
이번 미션에서 테스트의 종류를 정의해보자면 이렇게 있습니다.

smoke 테스트: 대상이 잘 배포되어 동작하는지만 검증하는 테스트
e2e 테스트: 외부 시스템과 연동이 잘 되어있는지만 검증하는 테스트
acceptance 테스트: 시나리오가 잘 동작하는지 검증하는 테스트
kiosk-product는 kiosk → admin → DB 동작 여부를 확인하는 테스트가 맞을까요?
그렇다면 smoke, e2e, acceptance를 폴더로 구분해주면 좋을 것 같아요!
개발을 하다보면 단계에 맞는 테스트를 검증해야하는데 폴더로 테스트 계층이 구분되어있으면 특정 상황에 필요한 테스트만 돌려볼 수 있습니다!
참고로 health-check 부분은 아마 smoke에 해당할 것 같네요!
```