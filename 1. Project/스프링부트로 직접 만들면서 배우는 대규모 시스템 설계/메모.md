

**Monolithic Architecture**
- 모든 기능이 단일 코드베이스로 결합된 아키텍처
- 소규모 시스템에서 개발 및 배포가 간단하기 때문에 많이 선택
	- 빠르고 효율적으로 개발할 수 있음
- 하지만
	- 특정 부분만 확장하기 어려움
	- 변경사항이 시스템 전체에 영향을 미침
	- 대규모 시스템에서 복잡도가 커지고 개발이 어려움 
- 이러한 문제를 해결하기 위해 Microservice Architecture를 살펴봄


**Microservice Architecture**
- 시스템이 작고 독립적인 서비스(Microservice)로 구성 
- 각 서비스는 단일 기능을 담당하며, 독립적 배포 가능
	- 우리의 시스템에서는 
		- 게시글, 댓글, 좋아요, 조회수, 인기글, 게시글 조회 
		- 각 요구사항(기능)을 독립된 마이크로 서비스로 볼 수도 있다
- 서비스 단위로 유연한 확장 가능
- 하지만 
	- 서비스 간 복잡한 통신 및 모니터링 필요
	- 데이터 일관성 및 트랜잭션 관리의 어려움
	- 어려운 개발 난이도


|              | 모놀리틱       | MSA             |
| ------------ | ---------- | --------------- |
| **구조**       | 통합         | 분산              |
| **결합도**      | 높음         | 낮음              |
| **확장성**      | 개별 확장 어려움  | 개별 확장 쉬움        |
| **배포**       | 통합 배포      | 독립 배포           |
| **기술 스택**    | 단일 기술 스택   | 여러 기술 스택 가능     |
| **변경 전파 범위** | 시스템 전체     | 서비스 또는 전파 범위 이내 |
| **통신 비용**    | 낮음         | 높음              |
| **개발 난이도**   | 쉬움(소규모일수록) | 어려움             |

> [!note] MSA는 서비스간 통신 비용, 트랜잭션 관리, 서비스 분리 기준, 모니터링, 개발 비용, 테스트, 설계 등 고려해야 할 부분이 엄청 많다


**Docker**
- 애플리케이션을 컨테이너라는 격리된 환경에서 실행할 수 있게 해주는 플랫폼
	- 쉽게 배포하고 관리할 수 있음 
	- 환경에 구애 받지 않음

**프로젝트 구조**
```text
board 
	- service: 하위 모듈로 각 마이크로서비스를 가짐
		- article: 게시글 서비스
		- comment: 댓글 서비스
		- like: 좋아요 서비스
		- view: 조회수 서비스
		- hot-article: 인기글 서비스
		- article-read: 게시글 조회 서비스
	- common: 하위 모듈로 개발 편의를 위한 공통 코드를 관리
```


**프로젝트 생성**
- 스프링부트 - 멀티 모듈 프로젝트 

|              | 포트   |
| ------------ | ---- |
| article      | 9000 |
| comment      | 9001 |
| like         | 9002 |
| view         | 9003 |
| hot article  | 9004 |
| article read | 9005 |
| article read | 9006 |

```shell
$ sdk use java 21.0.3-ms

$ spring shell

$ init --list 

$ init -a board -g com.example -n board --package-name com.example.board -p jar -j 21 -b 3.3.2 -x board -d lombok,web
```
-x : jdbc 폴더에 프로젝트 생성
-d : dependency, **spring shell**에서  **init --list** 통해서 supported dependencies 확인 

---
## 섹션2. 게시글
### Distributed Relational Database
- **샤딩(Sharding)**: 데이터를 여러 DB에 분산하여 저장하는 기술
	- 수직 샤딩(Vertical Sharding): 
		- 데이터를 수직으로 분할하는 방식(**컬럼 단위**)
		- 각 샤드별로 테이블에 기본키가 존재하고 컬럼을 나눠서 관리
		- 각 샤드가 적은 수의 컬럼을 저장하므로, 성능 및 공간 이점이 생긴다
		- 하지만, <u>데이터 분리로 인해 조인 또는 트랜잭션 관리가 복잡</u>해질 수 있다
		- 그리고 <u>수직으로 분할되므로 수평적 확장에 제한</u>이 있다
	- 수평 샤딩(Horizontal Sharding)
		- 데이터를 수평으로 분할하는 방식(**행 단위**)
		- 예로 두 샤드가 있을 때 `id = 1 ~ 5000`, `id = 5001 ~ 10000` 각각 관리
		- 각 샤드에 데이터가 분산되므로 성능 및 공간 이점이 생긴다
		- 하지만 데이터의 분리로 인해 조인 또는 트랜잭션 관리가 복잡해질 수 있다.
		- 수평으로 분할되므로 수평적 확장에 용이하다.
- **샤드(Shard)**: 샤딩된 각각의 데이터 단위


|         | 수직샤딩                           | 수평 샤딩         |
| ------- | ------------------------------ | ------------- |
| **샤딩**  | 수직으로 분할(컬럼 단위)                 | 수평으로 분할(행 단위) |
| **확장성** | 제한                             | 용이            |
| **장점**  | 각 샤드로 데이터 분산되므로 성능 및 공간 이점(공통) | -             |
| **단점**  | 조인 또는 트랜잭션 고나리 등의 어려움(공통)      | -             |

**기법** 
- Range-based Sharding:
	- 데이터 쏠림 현상 발생 가능
- Hash-based Sharding(해시 기반 샤딩)
	- 균등한 분산을 위한 shard key와 해시 함수가 필요하다
	- 범위 데이터 조회에 불리할 수 있다.
- Directory-based Sharding(디렉토리 기반 샤딩)
	- 디렉토리 관리 비용이 있지만, 데이터 규모에 따라 유연한 관리가 가능

**물리적 샤드**
- 샤드 개수가 늘어나면 해시 함수 통해 재배치 발생

**논리적 샤드**
- 물리적 샤드가 2개이지만 가상의 샤드 4개가 있을 수 있다
- client는 router를 통해 4개 논리적 샤드에 요청이 가게 된다


|         | 물리적 샤드                | 논리적 샤드                                 |
| ------- | --------------------- | -------------------------------------- |
| **정의**  | 데이터를 물리적으로 분산한 실제 단위  | 데이터를 논리적으로 분산한 가상의 단위                  |
| **필요성** | 대규모 데이터 분산 저장 및 성능 향상 | 물리적 확장시, client 변경없이 유연한 매핑(router 위임) |

>[!note] 고가용성을 확보하기 위한 복제 
>primary/replica, leader/follower, master/slave, main/standby 등 유사한 개념이지만, 시스템이나 목적에 따라 다르게 사용되기도 한다.

이러한 복제는 동기적, 비동기적으로 처리 될 수 있다.
- 동기적(Synchronous): 데이터 일관성을 보장하나, 쓰기 성능 저하된다
- 비동기적(Asynchronous): 쓰기 성능 유지되나, 복제본에 최신 데이터가 즉시 반영되지 않을 수 있다.


**Primary Key 선택**
- 오름차순 유니크 숫자를 만들기 위한 알고리즘으로 Snowflake 선택
	- 그외 TSID 등이 있다
- Snowflake
	- X(전 트위터)에서 개발 
	- 분산 시스템에서 고유한 64비트 ID를 생성하는 알고리즘
		- `[1비트][41비트: 타임스탬프][10비트: 노드 ID][12비트: 시퀀스 번호]`
		• 분산 환경에서도 중복 없이 순차적 ID 생성하기 위한 규칙
			• 타임스탬프 : 순차성
			• 노드ID + 시퀀스 번호 : 고유성
	• 유니크, 시간 기반 순차성, 분산 환경에서의 높은 성능

---
### 조회 쿼리 성능 개선
**게시글 목록 조회 방식 2가지**
- 페이지 번호, 무한 스크롤


**페이지 번호** 
- N번 페이지에서 M개의 게시글: SQL offest, limit 사용
- <u>offest 지점부터 limit개 데이터 조회</u>

```sql
select * from article 
where board_id = {board_id}
order by created_at desc
limit {limit} offset {offset};
```
- 3초 걸림


> **explain** 명령어를 사용하면 쿼리 플랜을 확인할 수 있다
- `type = ALL`
	- 테이블 전체를 읽는다(full scan)
- `Extra = Using where; Using filesort`
	- where절로 조건 필터링
	- 데이터가 많기 때문에 메모리에서 정렬을 수행할 수 없어서, 파일(디스크)에서 데이터를 정렬하는 **filesort** 수행

**인덱스에 대한 이해**
- 데이터를 빠르게 찾기 위한 방법
- 인덱스 관리를 위해 부가적인 쓰기 작업과 공간이 필요
- 다양한 데이터 특성과 쿼리를 지원하는 자료구조
	- B+ tree, Hash, LSM tree, R tree, Bitmap
- Relational Database에서는 주로 `B+ tree(밸런스 트리)` 사용
	- 데이터가 정렬된 상태로 저장된다
	- 검색, 삽입, 삭제 연산을 로그 시간에 수행 가능
	- 트리 구조에서 leaf node 간 연결되기 때문에 범위 검색 효율적
- 인덱스를 추가하면
	- 쓰기 시점에 B+ tree 구조의 정렬된 상태의 데이터가 생성된다
	- 이미 인덱스로 지정된 컬럼에 대해 정렬된 상태를 가지고 있기 때문에 
		- 조회 시점에 전체 데이터를 정렬하고 필터링할 필요가 없다
		- 따라서 조회 쿼리를 빠르게 수행할 수 있다

**인덱스 생성**
- 게시판 별로 최신순으로 정렬
- `board_id`: 오름차순, `article_id`: 내림차순 
- 인덱스는 순서가 중요
```sql
create index idx_board_id_article_id on article(board_id asc, article_id desc);
```

**인덱스를 위와 같이 생성한 이유**
- 대용량 트래픽을 고려해서 설계 중
- 동시 요청시에 생성 시간은 충돌 될 수 있다
	- 따라서 created_at을 정렬조건으로 사용한다면, 시간에 따라 순서가 명확하지 않을 수 있다
	- 목록 조회에 대한 결과값이 달라질 수 있다
	- 데이터의 중복 또는 누락의 가능성
- 밀리/나노초 단위의 더욱 정밀한 데이터 타입을 가진다고 해도,
	- 확률은 줄어들지만 시간 충돌 문제는 여전하고, 저장공간만 더 필요해질 수 있다
- article_id는 분산시스템에서 고유한 오름차순을 위해 고안된 **알고리즘(snow flake)** 을 사용한다
	- <u>충돌 확률이 완전히 0은 아니지만, 생성 시간(created_at)보다 충돌 가능성이 현저히 적다</u>
	- 오름차순으로 생성 시간에 의해 정렬된 상태를 가지고 있다
	- 따라서 article_id를 최신 순(내림차순)으로 정렬할 수 있다

**수정된 SQL Query**
```sql
select * from article 
where board_id = {board_id}
order by article_id desc
limit {limit} offset {offset};
```
- 0.01 초 걸림
- query plan 분석시 
	- `key = idx_board_id_article_id` 로 생성한 인덱스가 쿼리에 사용된 것을 확인할 수 있다
- 이것으로 끝인걸까? 아래 쿼리를 실행해보자


```sql
select * from article 
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
- 2.79초 걸림(다시 느려짐)
- qurey plan 확인시 인덱스는 그대로 사용중
	- `offset`만 다를뿐
- 동작 순서
	- 1. Secondary Index에서 article_id(기본키)를 찾는다
	- 2. Clustered Index에서 article 데이터를 찾는다 
	- 3. offset 1499970을 만날 때까지 반복하며 skip 한다.
	- 4. limit 30개를 추출한다.

**인덱스에 대한 이해**
- MySQL 기본 스토리지 엔진
	- InnoDB
	- 스토리지 엔진(Storage Engine): DB에서 데이터 저장 및 관리 장치
- 그리고, InnoDB는 테이블마다 `Clustered Index`를 자동 생성한다
	- Primay key를 기준으로 정렬된 Clustered Index 
	- `Clustered Index` 는 leaf node의 값으로 **행 데이터(row data)** 를 가진다
		- 이는 곧 추가 탐색이 필요 x
- 반면 신규 생성한 인덱스는 `Non-Clustered Index`, `Secondary Index`(보조 인덱스)라고 부른다
	- `Secondary Index`는 leaf node에 데이터에 접근하기 위한 **포인터**를 가진다
		- Clustered Index의 데이터에 접근하기 위한 포인터
		- 즉, Primary key로 볼 수 있다.

|     | `Clustered Index`       | `Non-Clustered Index`        |
| --- | ----------------------- | ---------------------------- |
| 생성  | 테이블의 primary key로 자동 생성 | 테이블의 컬럼으로 직접 생성              |
| 데이터 | 행 데이터(row data)         | 데이터에 접근하기 위한 포인터, 인덱스 컬럼 데이터 |
| 개수  | 테이블 당 1개만               | 테이블 당 여러 개 생성가능              |
데이터는 `Clustered Index`가 가지고 있기 때문에 `Non-Clustered Index`를 타면 포인터를 가지고 다시 `Clustered Index`를 타게 된다 (offset 수 만큼 데이터에 접근하는 것도 비효율적이네)


**SQL Query (Covering Index)**
```sql
select board_id, article_id from article 
where board_id = 1
order by article_id desc
limit 30 offset 1499970;
```
- 0.2초 수행
- query plan
	- 동일하게 인덱스 사용
	- `Extra = Using Index` 가 추가되었는데, 인덱스만 사용해서 데이터를 조회했음을 의미
	- 이렇게 인덱스의 데이터만으로 조회를 수행할 수 있는 인덱스를 `Covering Index`라고 한다

**Covering Index**
- 인덱스만으로 쿼리의 모든 데이터를 처리할 수 있는 인덱스
- 데이터(Clustered Index)를 읽지 않고, 인덱스(Secondary Index) 포함된 정보만으로 쿼리 가능한 인덱스

**수정된 SQL Query**
```sql
select * from (
	select board_id, article_id from article 
	where board_id = 1
	order by article_id desc
	limit 30 offset 1499970
) t left join article on t.article_id = article.article_id;
```
- 0.15초 만에 수행


<font color="#ff0000">하지만 뒷 페이지로 갈 수록 속도가 또 느려짐</font>
```sql
select * from (
	select board_id, article_id from article 
	where board_id = 1
	order by article_id desc
	limit 30 offset 8999970
) t left joint article on t.article_id = article.article_id;
```
- article_id를 추출하기 위해 Seconday Index만 탄다고 하더라도 offset만큼 Index Scan이 필요하다
- <u> 고로 데이터에 접근하지 않더라도 offset이 늘어날 수록 느려질 수 밖에 없는 것이다</u>
- 방안1. 데이터를 한번 더 분리한다.
	- 예를 들면, 게시글을 1년 단위로 테이블 분리 
		- 개별 테이블의 크기를 작게 만듦
		- 각 단위에 대해 전체 게시글 수를 관리함
	- offset을 인덱스 페이지 단위 skip 하는 것이 아니라, 1년동안 작성된 게시글 수 단위로 즉시 skip 한다
		- 조회하고자 하는 offset이 1년동안 작성된 게시글 수 보다 크다면,
			- 해당 개수만큼 즉시 skip
			- 더 큰 단위로 skip을 수행하게 되는 것
		- 애플리케이션에서 이처럼 처리하기 위한 코드 작성 필요
- 방안2. 정책으로 풀어내기
	- 30만번 페이지를 조회하는게 정상적인 사용자 일까?
	- 데이터 수집을 목적으로 하는 어뷰저일 수도 있다.
	- 정책으로 게시글 목록 조회는 10,000번 페이지까지 제한한다
	- 시간 범위 또는 텍스트 검색 기능을 제공할 수도 있다
		- 더 작은 데이터 집합 내에서 페이징을 수행한다
- 방안3. 무한 스크롤 방식
	- 뒷 페이지를 가더라도 **균등한** 조회 속도를 가진다

---

게시글 건수 조회시 **1,200만건**이나 되면 <font color="#ff0000">1초</font>가 걸림 
- 그런데 이러한 사용처에서 모든 게시글 수가 필요할지는 의문이다
	- 우리는 전체 게시글 수가 필요한 것이 아니다 
	- 이동 가능한 페이지 번호 활성화에 필요한 것이다. // 건수 노출하지 않는 경우
- 페이지 당 30개의 게시글 노출, 10 페이지씩 이동 가능한 상황에서 
	- 사용자가 1 ~ 10번 페이지에 있을 경우 301개의 게시글 유무만 알면 된다
		- 301개면 다음 버튼 활성화, 301개 미만이면 개수만큼 페이지 버튼 활성화
	- 사용자가 11 ~ 20번 페이지에 있을 경우 601개의 게시글 유무만 알면 된다
		- 601개면 다음 버튼 활성화, 601개 미만이면 개수만큼 페이지 버튼 활성화 
- 이동 가능한 페이지 번호의 활성화를 위해 모든 게시글의 개수를 알 필요가 없다
	- <u>사용자의 현재 페이지 기준으로, 게시글 개수의 일부만 확인하면 된다 !</u>

> 공식 = (((n - 1) / k) + 1) * m * k + 1
- `n` : 현재 페이지
- `m` : 페이지당 게시글 개수
- `k` : 이동 가능한 페이지 개수
- `((n - 1) / k)`의 나머지는 버림


```sql
select count(*)
from (
  select article_id from article where board_id = {board_id} limit {limit}
) t;
```
count query에서는 limit이 동작하지 않고 전체 개수를 반환하므로 
- sub query에서 `Covering Index`로 limit 만큼 조회하고 count 하는 방식

사용자가 10,001 ~ 10,010번 페이지에 있다고 가정하면 300,301(limit)개까지만 카운트 해볼 수 있다
- 실행시 `0.07초` 걸림 (전체 카운트는 거의 <font color="#ff0000">1</font>초)

```sql
select count(*)  from article where board_id = 1 limit 300301
// 1.67s

select article_id  from article where board_id = 1 limit 300301
// 0.08s

select count(*) from (
	select article_id  from article where board_id = 1 limit 300301
) t
// 0.08s
```

---
### 페이지 번호 방식
Native 쿼리로 ArticleRepository에 조회 쿼리 작성

---
### 무한 스크롤 방식
- 사용자가 게시글을 <font color="#ff0000">삭제/추가</font>할 경우 
	- 페이지 번호 방식을 사용하면 데이터가 <font color="#ff0000">중복/누락</font> 될 수 있다 (사용성 문제가 생김)
	- 이를 해결하기 위해서는 무한 스크롤 사용
- 무한 스크롤에서는 **기준점 포인터**를 사용
	- 1. 첫 페이지를 조회한 사용자는 마지막 조회한 데이터의 기준점을 알고 있다
	- 2. 다음 페이지를 불러 올 때 마지막 조회한 데이터의 기준점을 파라미터로 전달한다면?
	- 3. 데이터베이스에서는 기준점으로 쿼리를 수행한다
		- 이때 기준점에 생성된 인덱스르 통해 로그 시간에 접근할 수 있다
		- 즉, offset만큼 scan 하는 과정이 필요하지 않다. limit 개수를 즉시 추출할 수 있다
		- 따라서, 아무리 뒷 페이지로 가더라도, 균등한 속도를 보장할 수 있다
- <u>무한 스크롤에서는 몇 페이지까지 있는지 알 필요가 없으므로, 게시글 개수도 필요 없다</u>

```sql
select * from article
where board_id = {board_id} and article_id < {last_article_id}
order by article_id desc limit 30;
```
- query plan
	- `key = idx_board_id_article_id` 인덱스가 사용됨 (article_id 기준 내림차순)
	- 마지막 페이지 번호를 기준으로 조회해도 속도 빠름

---
### Primary Key 생성 전략

- DB auto increasement
	- 간단
	- 분산환경에서 기본키 중복 발생 가능 
- UUID
	- 랜덤한 값이라 중복/충돌 가능성은 낮음
	- 다만 DB 디스크 I/O 비용이 증가함
- Snowflake
	- 64 bit로 오름차순 정렬 기본으로 지원, 분산환경에서도 안전
	- 알고리즘 러닝 커브 

```text
 Snowflake
	- X(전 트위터)에서 개발 
	- 분산 시스템에서 고유한 64비트 ID를 생성하는 알고리즘
		- `[1비트][41비트: 타임스탬프][10비트: 노드 ID][12비트: 시퀀스 번호]`
		• 분산 환경에서도 중복 없이 순차적 ID 생성하기 위한 규칙
			• 타임스탬프 : 순차성
			• 노드ID + 시퀀스 번호 : 고유성
	• 유니크, 시간 기반 순차성, 분산 환경에서의 높은 성능
```

---

## 섹션3. 댓글
### 댓글 최대 2 depth - 테이블 설계
**댓글 요구사항**
- 댓글 조회, 생성, 삭제 API
	- 삭제
		- 하위 댓글이 모두 삭제되어야 상위 댓글을 삭제할 수 있다
			- 하위 댓글이 없으면, 댓글은 즉시 삭제된다.
			- 하위 댓글이 있으면, 댓글은 `삭제 표시`만 된다.
- 댓글 목록 조회 API
	- 계층형
		- 최대 2 depth 대댓글: `Adjacency list (인접 리스트) 방식`
		- 무한 depth 대댓글: `Path enumeration (경로 열거) 방식`
	- 계층별 오래된 순 정렬
	- 페이지 번호, 무한 스크롤

// 그림 자료 참고


```text
// mysql 컨테이너 접속 후 (container_name : board-mysql)
mysql> create database comment;
mysql> use comment;
```


```text
create table comment (
	comment_id bigint not null primary key,
	content varchar(3000) not null,
	article_id bigint not null,
	parent_comment_id bigint not null,
	writer_id bigint not null,
	deleted bool not null,
	created_at datetime not null
);
```

```text
// 계정 권한 확인
SHOW GRANTS FOR 'tester'@'%';

GRANT ALL PRIVILEGES ON comment.* TO 'tester'@'%';
// 또는 일부 권한만 부여 가능 
GRANT SELECT, INSERT, UPDATE, DELETE ON comment.* TO 'tester'@'%';

// 권한 적용
FLUSH PRIVILEGES;
```


**CommentApiTest**
- 어플리케이션 실행 후 직접 호출하는 방식 (Postman 대체 가능)
```text
commentId = 155659926230863872 // 부모  (parentId == commentId)
commentId = 155659926809677824 // 자식1
commentId = 155659926851620864 // 자식2
```
- 부모를 삭제할 경우 `deleted = true`로만 변경됨
- 자식1을 삭제할 경우 하위 댓글이 없으므로 바로 삭제됨 
- 자식2를 삭제할 경우 하위 댓글이 없으므로 바로 삭제되고, **부모 댓글**도 자식이 없으므로 삭제된다

**더미 데이터 초기화** 
- DataInitializer 테스트 클래스에서 멀티 스레드로 실행
- 100만개 삽입 완료(5분)

```java
@SpringBootTest  
public class DataInitializer {  
  
    private static final int BULK_INSERT_SIZE = 2000;  
    private static final int EXECUTE_COUNT = 5000;  
  
    @PersistenceContext  
    private EntityManager entityManager;  
  
    @Autowired  
    private TransactionTemplate transactionTemplate;  
  
    private final Snowflake snowflake = new Snowflake();  
    private final CountDownLatch latch = new CountDownLatch(EXECUTE_COUNT);  
  
    @Test  
    void init() throws InterruptedException {  
        ExecutorService executorService = Executors.newFixedThreadPool(10);  
  
        for(int i = 0; i < EXECUTE_COUNT; i++) {  
            executorService.submit(() -> {  
                insert();  
                latch.countDown();  
                System.out.println("latch.getCount() = " + latch.getCount());  
            });        }  
        latch.await();  
        executorService.shutdown();  
    }  
    private void insert() {  
        transactionTemplate.executeWithoutResult(status -> {  
            Comment prev = null;  
            for(int i = 0; i < BULK_INSERT_SIZE; i++) {  
                Comment comment = Comment.of(  
                        snowflake.nextId(),  
                        "content",  
                        i % 2 == 0 ? null : prev.getCommentId(),  
                        1L,  
                        1L  
                );  
                prev = comment;  
  
                entityManager.persist(comment);  
            }        });    }}
```


### 댓글 최대 2 depth - 목록 API 설계
- `commentId` 순으로 정렬하기에는 목적에 맞지 않다
- 즉, 상위 댓글은 항상 하위 댓글보다 먼저 생성되고, 하위 댓글은 상위 댓글 별 순서대로 생성된다 
	- 상위 댓글에 의해 순서가 명확하게 정해질 수 있는 것이다
	- `parent_comment_id = 1, comment_id = 1`
	- `parent_comment_id = 1, comment_id = 2`
	- `parent_comment_id = 1, comment_id = 4`
	- `parent_comment_id = 3, comment_id = 3`
	- `parent_comment_id = 3, comment_id = 5`
	- `(parent_comment_id 오름차순, comment_id 오른차순)` 정렬 구조를 가짐 
	- 이 정렬 순서를 이용하면 오래된 순 페이징 처리를 할 수 있다 

```text
create index idx_article_id_parent_comment_id_comment_id on comment (
	article_id asc, parent_comment_id asc, comment_id asc
);
```


**페이징 쿼리 생성**
1. N번 페이지에서 M개의 댓글 조회 (`커버링 인덱스 사용`)
```text
select * from (
	select comment_id from comment
	where article_id = {article_id}
	order by parent_comment_id asc, comment_id asc
	limit {limit} offset {offset}
) t left join comment on t.comment_id = comment.comment_id; 
```

2. 댓글 개수 조회 
```text
select count(*) from (
	select comment_id from comment where article_id = {article_id} limit {limit}
) t;
```


`page = 1, pageSize = 10, movablePageCount = 10` 일 pageLimit = 101 구해진다. 이를 위에 count(..) 조회시 101개가 조회되면 10 페이지만큼 페이징을 출력하면 된다는 의미인듯하다. 
```java
@NoArgsConstructor(access = AccessLevel.PROTECTED)  
public class PageLimitCalculator {  
  
    public static Long pageLimit(Long page, Long pageSize, Long movablePageCount) {  
        return (((page - 1) / movablePageCount) + 1) * pageSize * movablePageCount + 1;  
    }}
```


2depth 방식
```text
response.getCommentCount() = 101
comment.getCommentId() = 155867903444566016
	comment.getCommentId() = 155867903486509056
comment.getCommentId() = 155867903486509057
	comment.getCommentId() = 155867903486509058
comment.getCommentId() = 155867903486509059
	comment.getCommentId() = 155867903486509060
comment.getCommentId() = 155867903486509061
	comment.getCommentId() = 155867903486509062
comment.getCommentId() = 155867903486509063
	comment.getCommentId() = 155867903486509064
```

무한 스크롤 방식
```text
firstPage
comment.getCommentId() = 155867903444566016
	comment.getCommentId() = 155867903486509056
comment.getCommentId() = 155867903486509057
	comment.getCommentId() = 155867903486509058
comment.getCommentId() = 155867903486509059
secondPage
	comment.getCommentId() = 155867903486509060
comment.getCommentId() = 155867903486509061
	comment.getCommentId() = 155867903486509062
comment.getCommentId() = 155867903486509063
	comment.getCommentId() = 155867903486509064
```

---
### 댓글 무한 depth - 테이블 & 구현 설계 
> 내 생각에 유튜브 댓글은 depth 2로 제한된 Path Enumeration (경로 열거) 방식인듯 하다

```text
----------------------
parent_comment_id = 1 (root)
comment_id = 1
----------------------
parent_comment_id = 1 > 2
comment_id = 2
----------------------
parent_comment_id = 1 > 2 > 6
comment_id = 6
----------------------
parent_comment_id = 1 > 4
comment_id = 4
----------------------
parent_comment_id = 1 > 4 > 5
comment_id = 5
----------------------
parent_comment_id = 3 (root)
comment_id = 3
----------------------
parent_comment_id = 3 > 7
comment_id = 7
----------------------


```
- 단순하게 생각하면 각 depth 만큼 컬럼을 만들어서 각 depth별 댓글 id를 관리할 수도 있다
- 하지만 설계 구조상 depth는 무한할 수 있어야하는데, <font color="#ff0000">depth만큼 컬럼의 개수를 생성 관리한다면 테이블 구조가 복잡해질 수 있는 것이다. </font>
- 그래서 문자열 컬럼 1개로 이러한 경로 정보를 만들어본다 
- 각 depth에서 순서를 문자열로 나타내고, 이러한 문자열을 순서대로 결합하여 경로를 나타내는 것이다.
- `Path Enumeration(경로 열거)` 방식을 취할 수 있는 것이다.


```text

xxxxx | xxxxx | xxxxx | ....
1depth  2depth  3depth  4depth

- 문자열로 나타내기 때문에 반드시 10개의 숫자로 나타낼 필요x
- 각 자릿수 하나에 0~9(10개), a-z(26개), A-Z(26)개의 문자를 사용한다
- 이때 문자열 순서는 0~9 < A-Z < a-z
- 표현할 수 있는 경로의 범위가 각 경로별로 62^5 = 약 9.1억개로 제한된다
- '00000' ~ 'zzzzz' 까지 순서대로 생성됨 

```
- 이를 위해 데이터 베이스 `collation` 설정이 필요
- 문자열을 정렬하고 비교하는 방법을 정의하는 설정
	- 이는 대소문자 구분, 악센트 구분, 언어별 정렬 순서등을 포함
		- 데이터베이스, 테이블, 컬럼별 설정
- comment 테이블의 디폴트 collation 설정은? `utf8mb4_0900_ai_ci`

```text
select table_name, table_collation from information_schema.TABLES where table_schema = 'comment';
```

**utf8mb4_0900_ai_ci**
- utf8mb4 = 각 문자 최대 4바이트 utf8 지원
- 0900 = 정렬 방식 버전
- ai = 악센트 비구분
- <font color="#ff0000">ci = 대소문자 비구분</font>
- 지금 하려는 방식은 **대소문자 구분이 필요**하다 -> `utf8mb4_bin` 설정 사용
- `path` 컬럼 추가하여 아래 신규 테이블을 생성한다
	- *개발 편의 및 서비스 제한 사항으로 5depth로 제한* 
	- `varchar(25)` : 5depth * 5개 문자


```text
create table comment_v2 (
	comment_id bigint not null primary key,
	content varchar(3000) not null,
	article_id bigint not null,
	writer_id bigint not null,
	path varchar(25) character set utf8mb4 collate utf8mb4_bin not null,
	deleted bool not null,
	created_at datetime not null
);

create unique index idx_article_id_path on comment_v2(
	article_id asc, path asc
);
```
- path에 인덱스를 생성하여 정렬 데이터를 관리 (페이징에 사용가능)
- path는 독립적인 경로를 가지므로, 유니크로 생성한다
	- 애플리케이션의 동시성 문제를 막아줄 수 있을 것이다.


```text
SELECT table_name, column_name, collation_name
FROM information_schema.COLUMNS
WHERE table_schema = 'comment' and 
table_name = 'comment_v2' and
column_name = 'path';

+------------+-------------+----------------+
| TABLE_NAME | COLUMN_NAME | COLLATION_NAME |
+------------+-------------+----------------+
| comment_v2 | path        | utf8mb4_bin    |
+------------+-------------+----------------+
```


**Path 생성 규칙**
- `parentPath (00a0z)` 
	- `childrenTopPath (00a0z 00002)`
		- `descendantsTopPath (00a0z 00002 00000)`
- `childrenTopPath` 빠르게 잘 찾기 위해서
	- `descendantsTopPath`에서 쿼리 조회 후 뒤에 5자리를 자르면 된다
	- 아래 쿼리 참고

```text
select path from comment_v2
where article_id = {article_id}
	and path > {parentPath} // parent 본인은 미포함 검색 조건
	and path like {parentPath}% // parentPath를 prefix로 하는 모든 자손 검색 조건
order by path desc limit 1;
```
- 인덱스를 `article_id asc, path asc`로 생성했다
- 쿼리에서 `path desc` 를 수행하기 때문에 내림차순 정렬을 추가로 하는건 아닌지 염려해볼 수 있다
	- explain 키워드로 확인 결과 `Using where; Backward index scan; Using index`
		- `Using index` : 커버링 인덱스 사용
		- `Backward index scan`
			- 인덱스를 역순으로 스캔하는 것
			- 인덱스 트리 leaf node 간에 연결된 양방향 포인터를 활용한다
			- 정렬 상태를 가지고 있어 끝 기준점 또한 인덱스 트리에서 로그 시간에 찾을 수 있다
			- path desc 수행시 limit 1개만 찾으면 되므로, 역순으로 스캔을 시작한다
			- 결국 `descendantsTopPath`를 인덱스 덕분에 빠르게 찾을 수 있다 (자료 참고p364)


**path 계산하기**
- 방법1. 문자열 덧셈으로 구하기
	- 0 ~ z까지 대소관계를 정의하고, 오른쪽 문자부터 바꿔준다 
		- carry(올림수)가 없으면 처리 종료
		- carry(올림수)가 있으면 다음 문자로 처리
		- 이미 'zzzzz'라면 overflow
- **방법2. 숫자 덧셈으로 구하기 (이 방식 사용)**
	- 62진수 문자열을 10진수 숫자로 바꿔서 +1 한 다음에 숫자를 대응하는 문자열로 다시 바꿔준다

> 각 depth별로 'zzzzz'까지 모두 표현했다면, 문자열 개수나 문자 표현개수 늘리거나 하는 방식으로 대응 가능


**무한 depth - 페이지 번호 쿼리**
- 편의 위해 5 depth 제한
```text
select * from (
	select comment_id
	from comment_v2
	where article_id = {article_id}
	order by path asc
	limit {limit} offset {offset}
) t left join comment_v2 on t.comment_id = comment_v2.comment_id;


select count(*) from (
	select comment_id from comment_v2 where article_id = {article_id} limit {limit}
) t;
```

**무한 depth - 무한 스크롤**
```text
// 1 페이지 
select * from comment_v2
where article_id = {article_id}
order by path asc limit {limit};

// 2 페이지 이상 (기준점 last_path)
select * from comment_v2
where article_id = {article_id} and path > {last_path}
order by path asc
limit {limit};
```


CommentPath에서 
- 현재 path에서 `lastChunk` 는 뒤에서 5개를 구하네
- `lastChunk = 00000` 인 경우 
	- charsetLength = 62;
	- value = 1 (전부 0이니깐 인덱스도 0)
- `result = 00001`
	- 1
	- 01
	- 001
	- 0001
	- 00001

```text
lastChunk = "12345"

// 10진수 변환
int value = 0;
value = (0 * 62 + 1); // 1
value = 1 * 62 + 2; // 64
value = 64 * 62 + 3; // 3971
value = 3971 * 62 + 4; // 246026
value = 246026 * 62 + 5; // 15264777
value += 1 // 15264778

// 62진수 변환
String result = "";

result = CHARSET.charAt(15252998 % 62) + result; // "6"
value /= 62; // 246206

result = CHARSET.charAt(246206 % 62) + result; // "4" + "6"
value /= 62; // 3971

result = CHARSET.charAt(3971 % 62) + result; // "3" + "46"
value /= 62; // 64

result = CHARSET.charAt(64 % 62) + result; // "2" + "346"
value /= 62; // 1

result = CHARSET.charAt(1 % 62) + result; // "1" + "2346"
value /= 62; // 0

```

---

## 섹션4. 게시글 좋아요
**요구사항**
- 각 사용자는 각 게시글마다 1회만 좋아요를 누를 수 있다
	- 취소 가능
	- 1개의 고유한 데이터만 관리되어야 한다
- `유니크 인덱스`를 이용하면 이를 손쉽게 구현할 수 있다
- `(게시글 ID + 사용자 ID)`로 유니크 인덱스를 만들면 되는 것이다

```text
mysql> create database article_like;

mysql> GRANT ALL PRIVILEGES ON comment.* TO 'tester'@'%';
mysql> FLUSH PRIVILEGES;

mysql> use article_like;

mysql> create table article_like (
article_like_id bigint not null primary key,
article_id bigint not null,
user_id bigint not null,
created_at datetime not null
);

mysql> create unique index idx_article_id_user_id on article_like(article_id asc,
user_id asc);

```

**좋아요 수 설계**
- 대규모 데이터에서 count 쿼리의 성능 이슈는 앞서 살펴봄
	- 그리고, 게시글과 달리 일부 카운트만 보여줄 수도 없다
	- 좋아요 전체 개수는 실시간으로 빠르게 보여줘야 한다
- 조회 시점에 전체 개수를 실시간 조회하는데는 큰 비용이 든다면
	- 좋아요가 생성/삭제 될 때마다 미리 좋아요 수를 갱신해 두는 방법이 있다
- 좋아요(article_like) 테이블의 <u>게시글 별 데이터 개수를 미리 하나의 데이터로 비정규화</u>해두는 것이다.
- 쓰기 트래픽이 비교적 크지 않고, 일관성이 중요하다면
	- 관계형 DB의 트랜잭션을 활용해 볼 수 있다.
	- 좋아요 테이블의 `데이터 생성/삭제`와 `좋아요 수 갱신`을 하나의 트랜잭션으로 묶는 것이다.
	- 데이터베이스는 좋아요 테이블과 동일한 MySQL을 사용한다.
- 게시글 테이블에 좋아요 수 컬럼을 추가하고, 갱신한다. 
- 하지만 이 방식에 몇가지 제약이 있을 수 있다. (**섹션 4-3 참고**)
	- `record lock (Exclusive Lock)`: 락을 오해 점유하면 리소스 낭비 발생 가능
	- `분산락`
- 게시글과 좋아요 수의 변경은 Lifecycle이 다르다.
	- 게시글
		- 게시글을 작성한 사용자가 쓰기 작업을 수행한다
		- 트래픽은 상대적은 적다
	- 좋아요 수
		- 게시글을 조회한 사용자들이 쓰기 작업을 수행한다
		- 트래픽은 상대적으로 많다
- 지금 `좋아요`와 `좋아요 수` 데이터의 일관성을 위해 관계형 데이터베이스의 트랜잭션을 고려하고 있다.
- 트랜잭션은 보통 단일 DB 내에서 안정적이고 빠르게 지원한다. 
	- 분산된 시스템에서 트랜잭션을 지원하려면?
		- **분산 트랜잭션** 개념이 필요하다 -> 상대적으로 느리고 복잡할 수 있다 (`인기글`에서 다룸)
- 만약, 게시글 서비스의 DB에 좋아요 수 테이블을 관리한다면?
	- 분산 환경이기 때문에 트랜잭션 관리가 복잡해짐
	- 좋아요 서비스가 있는데, 게시글 서비스에서 관리할 이유가 없다.
- <u>따라서, 좋아요 서비스의 DB에 좋아요 수 테이블을 관리한다</u>
- **좋아요 수 테이블(article_like)** 의 Shard Key는 **좋아요 테이블(article_like_count)** 과 동일한 `article_id`로 한다


**좋아요 수 동시성 이슈(섹션4-4)**
높은 쓰기 트래픽이 들어오는 상황에서 `동시성 문제(데이터 중복, 유실)`가 발생할 수 있다 
- 이러한 문제가 해결될 수 있는 구현 방법이 필요하다
	- Lock을 이용하는 사례로서 DB의 Record Lock이 있다 (비관적 락)
	- update 문을 수행하면 record에 lock이 걸리는 것을 확인했다.
- `비관적 락`, `낙관적 락` , `비동기 순차 처리` 방식을 살펴본다 (`섹션4-4`)
	- `비동기 순차 처리` 방식은 다른 섹션에서 다룸
- 3가지 방법을 모두 구현해본다
	- 비관적 락1 : `update`
	- 비관적 락2 : `select for update + update`
	- 낙관적 락 : `version`
		- 좋아요 수 테이블에 version 컬럼을 생성한다 
		- jpa 사용

```text
pessimistic-lock-1 start
lockType = pessimistic-lock-1, time = 5223ms
pessimistic-lock-1 end
count = 3001

pessimistic-lock-2 start
lockType = pessimistic-lock-2, time = 8009ms
pessimistic-lock-2 end
count = 3001

optimistic-lock start
lockType = optimistic-lock, time = 4105ms
optimistic-lock end
count = 404 // 충돌로 인해 롤백 처리만 해서 카운트가 적음
```

➡️ **비관적 락 1이 비관적 락 2보다 빠른 이유**
- `UPDATE` 자체가 락을 걸면서 실행되므로 **불필요한 SELECT를 수행할 필요 없음**
	- 단점은 DeadLock 위험 있음
- `SELECT ... FOR UPDATE`는 트랜잭션 충돌 시 대기 시간이 증가
- `SELECT ... FOR UPDATE`는 추가적인 인덱스 검색 비용이 발생
	- 장점: 명시적으로 락 설정 가능
	- 단점: 느림(쿼리2개에 추가 I/O)


**게시글 수, 댓글 수 설계**
- 게시글 서비스와 댓글 서비스에도 구현해본다
	- 인기글 서비스에서 인기글 선정을 위해 필요하다
	- 여기서 비관적 락 방법 1을 사용한다

```text
// article (게시글 수), board_id가 shard key
create table board_article_count (
	board_id bigint not null primary key,
	article_count bigint not null
);

// comment (댓글 수)
create table article_comment_count (
	article_id bigint not null primary key,
	comment_count bigint not null
);
```
- board(게시판)별 article(게시글) count를 카운팅
	- create, delete 시에 카운트 증감시킴
- article별 comment count의 경우 V2에만 만듦 
	- create, delete 시에 카운트 증감시킴

---
## 섹션5. 조회수
- 조회수는 게시글이 조회된 횟수만 저장하면 된다
	- 좋아요 수, 게시글 수, 댓글 수처럼 다른 데이터의 개수로 파생되는 것이 아니다
	- 사용자는 내역을 확인하지 못하므로, 조회수만 보여주면 된다
		- 즉, 전체 조회수를 단일 레코드에 비정규화 상태로 바로 저장해도 충분할 것이다

**비교**
- 데이터 일관성 
	- 게시글/댓글/좋아요 수 : 비교적 중요하다
	- 조회수 : 비교적 덜 중요하다
- 쓰기 트래픽
	- 게시글/댓글/좋아요 수 : 비교적 적다
	- 조회수 : **비교적 많다**
- 게시글/댓글/좋아요 수는 트랜잭션을 지원하는 관계형 데이터 베이스를 사용함
	- 트랜잭션을 사용하여 데이터의 일관성을 지키고, 안전한 저장소(디스크)에 영구적으로 저장한다
	- 하지만 디스크 접근 비용과 트랜잭션 관리 비용이 생긴다
- 조회수는 
	- **데이터 일관성이 덜 중요**하고, 다른 데이터에 의해 파생되는 데이터가 아니다
	- 그래서 트랜잭션이나 안전한 저장소가 반드시 필요하진 않다
		- 관계형 DB의 트랜잭션이나 디스크를 사용하지 않을 수 있다
	- <font color="#ff0000">하지만 쓰기 연산으로 인해 상대적으로 트래픽이 많다</font>
		- 디스크는 접근 비용이 비싸다, 디스크보다 더 빠른 저장소인 메모리를 고려해볼 수 있다!
		- *섹션 5-1에서 Redis에 대해 간략 설명*
		- *그리고 Redis는 휘발성 메모리이기 때문에 백업 방식도 다루어 봄*

```shell
> docker run --name board-redis -d -p 6379:6379 redis:7.4
```


조회수 DB, 테이블 생성 
```text
mysql> create database article_view;

mysql> GRANT ALL PRIVILEGES ON article_view.* TO 'tester'@'%';
mysql> FLUSH PRIVILEGES;

mysql> use article_view;

mysql> create table article_view_count (
article_id bigint not null primary key,
view_count bigint not null
);
```


- 조회수 카운팅은 :  `redis` 
- 조회수 카운팅 백업은 : `mysql`
	- 정책은 카운팅 개수가 **100개** 마다 DB에 백업

### 조회수 어뷰징 방지 정책 
- 어뷰저는 특정 게시글을 여러 번 조회해서 데이터를 조작할 수 있다
	- 조회수 기반으로 인기글이 산정되는 경우 잘못된 정보 노출
- 어뷰징을 방지하기 위한 조회 여부는 어떻게 식별할 수 있을까?
	- 로그인 사용자 : 사용자 별로 식별
	- 비로그인 사용자: IP, User-Agent, 브라우저 쿠키, 토큰 등 다양한 방법으로 식별 
- 지금은 정책을 간소화하기 위해 **로그인 사용자에 대해서만 식별**한다
	- `userId` 사용
	- 구체적인 정책보단, 어뷰징을 방지하기 위한 구현 방법에 초점을 맞춘 것
- Redis에 `TTL(Time To Live) = 10분`으로 데이터 저장 후 자동 삭제
	- userId 활용해서 Redis에 락을 저장후 10분 생명주기를 가지도록 한다
		- 스프링부트는 무상태 (stateless) 애플리케이션이다
		- 락이 있으면 조회수 증가 x
		- 락이 없으면 조회수 증가 후 락 생성
	- `setIfAbsent`(데이터가 없을 때만 저장) > 성공하면 true, 실패하면 false 반환
		- 성공했으면, 조회내역이 없었음을 의미한다. 고로 조회수를 증가
		- 실패했으면, 조회내역이 있음을 의미한다. 고로 조회수를 증가X
	- <u>이러한 과정은 사용자의 게시글 조회수 증가에 대해서 Lock을 획득한다고 볼 수 있다</u>
	- 이렇게 분산 시스템에서 락을 획득하는 것을 **분산 락**이라고 한다

> [!summary] 
> 조회수 어뷰징 방지하기 위해 Redis에 userId 기반으로 lock을 생성하고 생명주기를 10분으로 한다
> 그리고 조회수 백업을 위해 RDB를 사용하고 카운팅이 100의 배수일 때마다 실행한다

- 결국 ViewApiTest에서 같은 articleId에 같은 userId로 조회수 증가 요청을 보내도 `count = 1`이 출력된다.

---

## 섹션6. 인기글 

**카프카 컨테이너 생성** 
```shell
$ docker run -d --name board-kafka -p 9092:9092 apache/kafka:3.8.0
```

**토픽 생성 (4개)**
```shell
```


**인기글 설계**
1. 인기글 선정에 필요한 이벤트를 스트림으로 받는다
2. 실시간으로 각 게시글의 점수를 계산한다 
3. 실시간으로 상위 10건의 인기글 목록을 만든다
4. Client는 인기글 목록을 조회한다

> Kafka 브로커를 통해 인기글 서비스가 연산 후 Redis에 저장하는 형태


인기글 구현 시
- `Producer` :  게시글/댓글/좋아요/조회수 서비스 
- `Consumer` : 인기글 서비스

---
### 트러블 슈팅
**문제** 
article 데이터베이스 생성 후 조회 테스트하는데 아래 에러 로그가 확인되었다.
> Encountered a duplicated sql alias [article_id] during auto-discovery of a native-sql query


**해결 방법**
https://stackoverflow.com/questions/78211463/encountered-a-duplicated-sql-alias-id-during-auto-discovery-of-a-native-sql-qu

찾아 보니 join 테이블에 각 article_id를 가지고 있다보니 충돌나서 에러가 출력된거였다. 

**before**
```java
@Query(  
        value = " select * from (" +  
                " select article_id from article " +  
                " where board_id = :boardId " +  
                " order by article_id desc " +  
                " limit :limit offset :offset " +  
                ") t left join article on t.article_id = article.article_id ",  
        nativeQuery = true  
)  
List<Article> findAll(  
        @Param("boardId") Long boardId,  
        @Param("offset") Long offset,  
        @Param("limit") Long limit  
);
```


**after**
```java
@Query(  
        value = " select article.article_id, article.title, article.content, article.board_id, article.writer_id, article.created_at, article.modified_at from (" +  
                " select article_id from article " +  
                " where board_id = :boardId " +  
                " order by article_id desc " +  
                " limit :limit offset :offset " +  
                ") t left join article on t.article_id = article.article_id ",  
        nativeQuery = true  
)  
List<Article> findAll(  
        @Param("boardId") Long boardId,  
        @Param("offset") Long offset,  
        @Param("limit") Long limit  
);

```

